{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set the kernel to \"Workshop Environment\" from the Jupyter Kernels.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Testing with Great Expectations\n",
    "\n",
    "## Introduction\n",
    "Data quality is the foundation of reliable analytics. Poor data leads to flawed insights and decisions. This workshop explores data quality testing using the powerful Great Expectations library.\n",
    "\n",
    "## Why Data Quality Matters\n",
    "- **Trust**: Quality data builds confidence in results\n",
    "- **Efficiency**: Early detection prevents downstream issues \n",
    "- **Consistency**: Ensures reliable model performance\n",
    "- **Governance**: Meets regulatory requirements\n",
    "\n",
    "## Our Approach\n",
    "Using the \"Bike Sharing\" dataset from UCI, we'll learn how to:\n",
    "- Define expectations about your data\n",
    "- Validate these expectations systematically\n",
    "- Document and report quality issues\n",
    "- Integrate quality checks into pipelines\n",
    "\n",
    "## Goals of this Workshop\n",
    "- Design valuable data quality checks to build the foundation of your flexible (AI) pricing system\n",
    "- Visually inspect expectations and keep track of expectations runs over time\n",
    "\n",
    "\n",
    "## Task 1: Explore the Dataset\n",
    "Let's begin by exploring the Bike Sharing dataset. Download the data, load it into a dataframe, and perform initial exploratory analysis to understand its structure and contents. This website provides detailed information about the dataset used: https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset. For this workshop, we made slight alterations to the columns of the dataset (to keep it simpler) and also denormalized measures like temperature etc to make it more intuitive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for data processing and quality testing\n",
    "# - great_expectations: Our primary tool for data quality validation\n",
    "# - sqlite3: To connect with our SQLite database\n",
    "# - pandas: For data manipulation and analysis\n",
    "import great_expectations as gx\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "from utils import database\n",
    "from utils.checker import check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the database with our bike sharing dataset\n",
    "# This sets up a SQLite database with the necessary tables and imports the data\n",
    "database.init()\n",
    "\n",
    "# Create a connection to our database for querying\n",
    "conn = sqlite3.connect(\"database.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Great Expectations context\n",
    "# This creates the environment where we define and validate expectations\n",
    "gx_context = gx.get_context()\n",
    "\n",
    "# Add our SQLite database as a data source for Great Expectations\n",
    "# This allows us to test data directly from the database\n",
    "data_source = gx_context.data_sources.add_sqlite(\n",
    "    \"sample\", connection_string=\"sqlite:///database.db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data asset we want to validate\n",
    "# An asset in Great Expectations represents a table or query result that we want to test\n",
    "asset_name = \"bike_rental\"\n",
    "database_table_name = \"bike_rental\"\n",
    "table_data_asset = data_source.add_table_asset(\n",
    "    table_name=database_table_name, name=asset_name\n",
    ")\n",
    "\n",
    "# Create a batch definition that specifies which data we want to validate\n",
    "# Here we're selecting the entire table for our first season (spring 2011)\n",
    "full_table_batch_definition = table_data_asset.add_batch_definition_whole_table(\n",
    "    name=\"0_spring_2011\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into a batch and display the first few rows\n",
    "# This gives us our first look at the structure and content of the dataset\n",
    "full_table_batch = full_table_batch_definition.get_batch()\n",
    "\n",
    "full_table_batch.head().data.loc[\n",
    "    :, [\"season\", \"weekday\", \"temp\", \"casual\", \"registered\", \"total\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the database directly to investigate potential data quality issues\n",
    "# Here we're looking for records where the 'casual' rider count equals 2\n",
    "# This helps us understand the distribution of this variable\n",
    "query = \"\"\"\n",
    "SELECT season, weekday, temp, casual, registered, total\n",
    "FROM bike_rental\n",
    "WHERE casual = 2\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Set Expectations for the Spring Data\n",
    "\n",
    "Now that you've explored the dataset, it's time to define your first expectations - the rules that your data should follow to be considered high quality.\n",
    "\n",
    "## Basic Expectations Examples\n",
    "\n",
    "Great Expectations provides various expectation types to validate different aspects of your data. Check out all available expectation in the gallery. https://greatexpectations.io/expectations/. Here are two examples:\n",
    "\n",
    "1. **Column Existence**\n",
    "   ```python\n",
    "   # Check that specific columns exist in your dataset\n",
    "   expect_column_to_exist(column=\"temp\")\n",
    "\n",
    "2. **Set Membership**\n",
    "   ```python\n",
    "   # Confirm categorical variables contain only allowed values\n",
    "   expect_column_values_to_be_in_set(\n",
    "       column=\"weathersit\", \n",
    "       value_set=[1, 2, 3, 4]  # 1:Clear, 2:Cloudy, 3:Light Rain, 4:Heavy Rain\n",
    "   )\n",
    "   ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Check if the 'season' column exists in the dataset\n",
    "# This is a fundamental check to ensure that our data has the expected structure\n",
    "# Hint: Set expectations like: \n",
    "# expectation = gx.expectations.XXX where XXX represents the expectation (see example above)\n",
    "\n",
    "### SOLUTION_START ###\n",
    "expectation = gx.expectations.ExpectColumnToExist(\n",
    "    column=\"season\",\n",
    ")\n",
    "### SOLUTION_END ###\n",
    "\n",
    "# Validate the expectation\n",
    "result = full_table_batch.validate(expectation, result_format=\"COMPLETE\")\n",
    "check(task=1, result=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Check if the season only contains Spring\n",
    "# This is a more specific check to ensure that the data is consistent with our expectations\n",
    "\n",
    "### SOLUTION_START ###\n",
    "expectation = gx.expectations.ExpectColumnValuesToBeInSet(\n",
    "    column=\"season\",\n",
    "    value_set=[\"Spring\"],\n",
    ")\n",
    "### SOLUTION_END ###\n",
    "\n",
    "# Validate the expectation\n",
    "result = full_table_batch.validate(expectation, result_format=\"COMPLETE\")\n",
    "print(\"The expectation result is: \", result[\"success\"])\n",
    "check(task=2, result=result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "The expectation failed because the 'season' column contains values other than 'Spring'. Let's investigate further by querying the distinct values in the 'season' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate why the expectation failed\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT season\n",
    "FROM bike_rental\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Task 3: Fix the data quality issue\n",
    "# Here we need to remove records that do not meet our expectation\n",
    "# This is a critical step to ensure that our dataset is clean and reliable\n",
    "# We will delete records where the season is not 'Spring'\n",
    "# Hint: use a sql delete statement in the query\n",
    "\n",
    "### SOLUTION_START ###\n",
    "query = \"\"\"\n",
    "DELETE FROM bike_rental\n",
    "WHERE season != 'Spring'\n",
    "\"\"\"\n",
    "### SOLUTION_END ###\n",
    "\n",
    "# Execute the DELETE query to remove records that do not meet the expectation\n",
    "with conn:\n",
    "    conn.execute(query)\n",
    "\n",
    "# Re-run the validation after fixing the data\n",
    "full_table_batch = full_table_batch_definition.get_batch()\n",
    "result = full_table_batch.validate(expectation, result_format=\"COMPLETE\")\n",
    "print(\"The expectation result is: \", result[\"success\"])\n",
    "\n",
    "check(task=3, result=result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, you didn't sign up for this Workshop just to see a fancy way of doing exactly the same as your basic unit test is doing, so let's get into more complex stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Task 4: Add another expectation for the max expected number of hourly bike data per day\n",
    "# Remember that the dataset already shows aggregated hourly data in the column \"total\"\n",
    "\n",
    "# Write the query to find the min and max\n",
    "\n",
    "### SOLUTION_START ###\n",
    "query = \"\"\"\n",
    "SELECT min(total), max(total) \n",
    "FROM bike_rental\n",
    "\"\"\"\n",
    "### SOLUTION_END ###\n",
    "\n",
    "# Execute the query\n",
    "print(pd.read_sql_query(query, conn))\n",
    "\n",
    "# Set the Max to be between 0.9*Max and 1.1*Max from the query before\n",
    "### SOLUTION_START ###\n",
    "expectation = gx.expectations.ExpectColumnMaxToBeBetween(\n",
    "    column=\"total\",\n",
    "    min_value = 0.9*638,\n",
    "    max_value = 1.1*638,\n",
    ")\n",
    "### SOLUTION_END ###\n",
    "\n",
    "# TODO: add validate check\n",
    "# Validate the expectation\n",
    "result = full_table_batch.validate(expectation, result_format=\"COMPLETE\")\n",
    "check(task=4, result=result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Adjust and Set New Expectations for the Summer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "database.set_step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Create a batch definition that specifies which data we want to validate\n",
    "# Here we're selecting the entire table for our first season (spring 2011)\n",
    "full_table_batch_definition = table_data_asset.add_batch_definition_whole_table(\n",
    "    name=\"1_summer_2011\",\n",
    ")\n",
    "\n",
    "# Setup for the batch\n",
    "full_table_batch = full_table_batch_definition.get_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate why the expectation failed\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT season\n",
    "FROM bike_rental\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excursion: Data Docs\n",
    "You might have noticed that at the moment, we just ran expectations and validated them. But it would be great to define a set of expectations and validate all of them at the same time. It would be even greater, if we could somehow visualise these results over time. This subchapter addresses these issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cheatsheet for GX Concepts\n",
    "- ***Batch***: A slide of data you want to validate\n",
    "- ***Validator***: A tool that lets you work with a batch interactively and build expectations\n",
    "- ***Expectation***: A rule or assertion about your data  \n",
    "- ***Expectation Suite***: A collection of expectations (think: Test suite)  \n",
    "- ***Data Docs***: HTML reports showing validation results  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "                 +----------------+\n",
    "                 |   Datasource   |\n",
    "                 +----------------+\n",
    "                          |\n",
    "                          v\n",
    "                 +---------------------+\n",
    "                 |   Data Connector    |\n",
    "                 +---------------------+\n",
    "                          |\n",
    "                          v\n",
    "                 +----------------+\n",
    "                 |     Batch      | <------------+\n",
    "                 +----------------+              |\n",
    "                          |                      |\n",
    "        +-----------------+                      |\n",
    "        |                                        |\n",
    "        v                                        |\n",
    "+----------------+        uses         +------------------------+\n",
    "|  BatchRequest  |-------------------> |      Validator         |\n",
    "+----------------+                    +------------------------+\n",
    "                                              |\n",
    "                                              v\n",
    "                               +-----------------------------+\n",
    "                               |     Expectation Suite       |\n",
    "                               +-----------------------------+\n",
    "                                              |\n",
    "                                              v\n",
    "                             +------------------------------+\n",
    "                             |     Validation Results       |\n",
    "                             +------------------------------+\n",
    "                                              |\n",
    "                                              v\n",
    "                               +------------------------+\n",
    "                               |      Data Docs         |\n",
    "                               +------------------------+\n",
    "                        \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notice\n",
    "\n",
    "If you get an error like this:  \n",
    "\"DataContextError\": Cannot add ExpectationSuite with name xxx, because it already exists   \n",
    "This appears because the cell was called twice.  \n",
    "To solve the issue, just give the suite a new name (for example add \"_1\" to it or something similar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define an expectation suite\n",
    "# First, we create an expectation Suite to gather all our expectations in one place\n",
    "suite_name = \"summer_suite\"\n",
    "expectation_suite = gx.ExpectationSuite(name=suite_name)\n",
    "\n",
    "# Second, we add two expectations to the expectation suite\n",
    "expectation_suite.add_expectation(gx.expectations.ExpectColumnValuesToNotBeNull(column = 'total'))\n",
    "expectation_suite.add_expectation(gx.expectations.ExpectColumnValuesToNotBeNull(column = 'dteday'))\n",
    "\n",
    "# Add the suite to the context\n",
    "expectation_suite = gx_context.suites.add(expectation_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get our batch definition (we've already defined it before)\n",
    "batch_def = full_table_batch_definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the validator\n",
    "validation_name = \"summer_validator\"\n",
    "\n",
    "validation_def = gx.ValidationDefinition(\n",
    "    data = batch_def,\n",
    "    suite = expectation_suite,\n",
    "    name = validation_name\n",
    ")\n",
    "\n",
    "# Add it the the context\n",
    "validation_def = gx_context.validation_definitions.add(validation_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the results\n",
    "validation_results = validation_def.run()\n",
    "print(validation_results)\n",
    "\n",
    "# Hint: Click on open in a text editor to view the whole output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the visualization file\n",
    "data_doc_dir = gx_context.build_data_docs()['local_site']\n",
    "print(data_doc_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: move this to utils and add to container build\n",
    "import os\n",
    "import webbrowser\n",
    "from http.server import HTTPServer, SimpleHTTPRequestHandler\n",
    "import threading\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def serve_docs(path, port=8000):\n",
    "    \"\"\"\n",
    "    Serve Great Expectations data docs on a local web server\n",
    "    \n",
    "    Args:\n",
    "        path (str): Path to the data docs directory\n",
    "        port (int): Port to serve on (default: 8000)\n",
    "    \"\"\"\n",
    "    # Parse the URL\n",
    "    parsed_url = urlparse(data_doc_dir)\n",
    "\n",
    "    # Extract the path and remove the file name\n",
    "    directory_path = os.path.dirname(parsed_url.path)\n",
    "\n",
    "    # Change to the data docs directory\n",
    "    os.chdir(directory_path)\n",
    "    \n",
    "    # Create server\n",
    "    server = HTTPServer(('localhost', port), SimpleHTTPRequestHandler)\n",
    "    \n",
    "    # Start server in a separate thread\n",
    "    thread = threading.Thread(target=server.serve_forever)\n",
    "    thread.daemon = True  # This makes the thread exit when the main program exits\n",
    "    thread.start()\n",
    "    \n",
    "    url = f\"http://localhost:{port}\"\n",
    "    print(f\"Serving data docs at {url}\")\n",
    "    \n",
    "    # Open browser automatically\n",
    "    webbrowser.open(url)\n",
    "    \n",
    "    return server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serve the .html in the browser\n",
    "# TODO: need to properly end and reiterate the service when function is called twice\n",
    "# serve_docs(data_doc_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notice\n",
    "\n",
    "If you get an error like this:  \n",
    "\"OSError: [Errno 98] Address already in use\"\n",
    "This appears because the cell was called twice.  \n",
    "To solve the issue, restart the kernel and run the notebook again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the Webpage that just opened! You can click the validation with the given expectation suite (here the summer_suite) and look into all the validations that were run when calling the validator. Take some time playing around with the webpage and explore!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Summer Expectations\n",
    "Equiped with this knowledge, let's set up the summer expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise a expectations array, which contains all our expectations and can then be added to our suite\n",
    "expectations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5: First, add the expectation that the expected column values can now contain either \"Spring\" or \"Summer\"\n",
    "# Hint: Look at Task 1 and follow the pattern.\n",
    "\n",
    "### SOLUTION_START ###\n",
    "expectation = gx.expectations.ExpectColumnValuesToBeInSet(\n",
    "    column=\"season\",\n",
    "    value_set=[\"Spring\", \"Summer\"],\n",
    ")\n",
    "### SOLUTION_END ###\n",
    "\n",
    "expectations.append(expectation)\n",
    "\n",
    "# TODO: Generate the task validation check\n",
    "# Validate the expectation (to see if the task was done correctly)\n",
    "# result = full_table_batch.validate(expectation, result_format=\"COMPLETE\")\n",
    "# check(task=5, result=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 6: Copy Paste the Expectation set in Task 4 and add it to our expectations array.\n",
    "# We want to check if the expectations hold up for summer rush.\n",
    "\n",
    "# Copy Paste Solution from Task 4\n",
    "### SOLUTION_START ###\n",
    "expectation = gx.expectations.ExpectColumnMaxToBeBetween(\n",
    "    column=\"total\",\n",
    "    min_value = 0.9*638,\n",
    "    max_value = 1.1*638,\n",
    ")\n",
    "### SOLUTION_END ###\n",
    "\n",
    "expectations.append(expectation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the expectations to our suite\n",
    "for exp in expectations:\n",
    "    expectation_suite.add_expectation(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the validator\n",
    "validation_name = \"summer_validator_updated\"\n",
    "\n",
    "# Define the validator\n",
    "### SOLUTION_START ###\n",
    "validation_def = gx.ValidationDefinition(\n",
    "    data = batch_def,\n",
    "    suite = expectation_suite,\n",
    "    name = validation_name\n",
    ")\n",
    "### SOLUTION_END ###\n",
    "\n",
    "# Add it the the context\n",
    "validation_def = gx_context.validation_definitions.add(validation_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the results by running the validator\n",
    "### SOLUTION_START ###\n",
    "validation_results = validation_def.run()\n",
    "print(validation_results)\n",
    "### SOLUTION_END ###\n",
    "\n",
    "# Hint: Click on open in a text editor to view the whole output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the visualization file\n",
    "data_doc_dir = gx_context.build_data_docs()['local_site']\n",
    "print(data_doc_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serve the .html in the browser\n",
    "# TODO: need to be navigated back to our directory, if you leave this in, then database.set_step can not find the folder data\n",
    "# serve_docs(data_doc_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Adjust for Autumn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database.set_step(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a batch definition that specifies which data we want to validate\n",
    "# Here we're selecting the entire table for our first season (spring 2011)\n",
    "full_table_batch_definition = table_data_asset.add_batch_definition_whole_table(\n",
    "    name=\"2_fall_2011\",\n",
    ")\n",
    "\n",
    "# Setup for the batch\n",
    "full_table_batch = full_table_batch_definition.get_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 7: Let's look at the bike rental trends! \n",
    "# Calculate the current mean of total bike rentals per ***month*** \n",
    "# Hint: the mean can be calculated using avg() in SQL\n",
    "\n",
    "### SOLUTION_START ###\n",
    "query = \"\"\"\n",
    "SELECT mnth, avg(total)\n",
    "FROM bike_rental\n",
    "Group By  mnth\n",
    "\"\"\"\n",
    "### SOLUTION_END ###\n",
    "\n",
    "# Execute the query\n",
    "print(pd.read_sql_query(query, conn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Definitions \n",
    "We will now introduce the concept of batch definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite_name = \"fall_suite\"\n",
    "expectation_suite = gx.ExpectationSuite(name=suite_name)\n",
    "\n",
    "# Second, we add two expectations to the expectation suite\n",
    "expectation_suite.add_expectation(gx.expectations.ExpectColumnValuesToNotBeNull(column = 'total'))\n",
    "expectation_suite.add_expectation(gx.expectations.ExpectColumnValuesToNotBeNull(column = 'dteday'))\n",
    "\n",
    "# Add the suite to the context\n",
    "expectation_suite = gx_context.suites.add(expectation_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's define an expected mean per month\n",
    "\n",
    "# Fill in the mean of october\n",
    "### SOLUTION_START ###\n",
    "mean_october = 166\n",
    "### SOLUTION_END ###\n",
    "\n",
    "# We set the expectation of the value range of the mean for october\n",
    "suite_name = \"october_expectation_suite\"\n",
    "\n",
    "# Create the expectation for october\n",
    "expectation_october = gx.expectations.ExpectColumnMeanToBeBetween(\n",
    "    column='total',\n",
    "    min_value=0.8*mean_october,\n",
    "    max_value=1.2*mean_october\n",
    ")\n",
    "\n",
    "# Create the suite and add the expectation\n",
    "expectation_suite = gx.ExpectationSuite(name=suite_name)\n",
    "expectation_suite.add_expectation(expectation_october)\n",
    "\n",
    "# Add the suite to the context\n",
    "expectation_suite = gx_context.suites.add(expectation_suite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This expectations needs to be applied to october only\n",
    "# We now introduce the concept of batch definitions\n",
    "# TODO: fix this, the data is not filtered correctly at the moment\n",
    "batch_definition_october = table_data_asset.add_batch_definition(\n",
    "    name=\"october_data\",\n",
    "    batch_kwargs={\n",
    "        \"query\": \"SELECT * FROM bike_rental WHERE mnth = 10\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Retrieve the batch for October\n",
    "batch_october = batch_definition_october.get_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batch\n",
    "batch_def_october = gx_context.get_batch_definition(\n",
    "    batch_kwargs={\"data\": batch_october, \"column_list\": [\"total\"]},\n",
    "    expectation_suite=expectation_suite\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the validator \n",
    "validation_name = \"october_validation\"\n",
    "validation_def = gx.ValidationDefinition(\n",
    "    data=batch_def_october,\n",
    "    suite=expectation_suite,\n",
    "    name=validation_name\n",
    ")\n",
    "\n",
    "validation_def = gx_context.validation_definitions.add(validation_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the validation\n",
    "validation_results = validation_def.run()\n",
    "\n",
    "# Build the visualization file\n",
    "data_doc_dir = gx_context.build_data_docs()['local_site']\n",
    "\n",
    "# Serve the .html in the browser\n",
    "# TODO: need to be navigated bac to our directory, if you leave this in, then database.set_step can not find the folder data\n",
    "# serve_docs(data_doc_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5: Check with Winter and set final expectations\n",
    "You can check out all kinds of expectations here: https://greatexpectations.io/expectations/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check the expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix what needs fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Maybe add something even more complex?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Recheck the Expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6: Verify your data and see if something shifts the next year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check the expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss these expectations => did you do a good job? What changed? Do you now have confidence in your data foundation for your AI model? Discuss pros and cons of using a Testing Framework!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 7: Think about AI Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could you now implement AI to design a flexible pricing model? How would you do it? What is the advantage over doing this by hand?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make this last part better and more to the point ^^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To stop the server when you're done (run this in another cell):\n",
    "# TODO: add function cleanup to utils which calls server.shutdown and cleans other things up if necessary\n",
    "# cleanup()\n",
    "# server.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
