{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT: Set the kernel to \"Workshop Environment\" from the Jupyter Kernels menu before running.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Testing with Great Expectations\n",
    "\n",
    "## Introduction\n",
    "Data quality is the cornerstone of reliable analytics and trustworthy AI systems. Poor quality data inevitably leads to flawed insights, inaccurate models, and poor decisions. This workshop provides a hands-on introduction to data quality testing using the powerful open-source library, Great Expectations.\n",
    "\n",
    "## Why Data Quality Matters\n",
    "- **Trust**: High-quality data builds confidence in analytical results and model predictions.\n",
    "- **Efficiency**: Detecting and fixing data issues early prevents costly downstream problems in ETL pipelines and model training.\n",
    "- **Consistency**: Ensures data reliability over time, leading to more stable and predictable model performance.\n",
    "- **Governance**: Helps meet data governance standards and regulatory requirements.\n",
    "\n",
    "## Our Approach in this Workshop\n",
    "We will use the \"Bike Sharing\" dataset from the UCI Machine Learning Repository. Throughout this workshop, you'll learn how to:\n",
    "- Define explicit expectations (rules) about your data.\n",
    "- Systematically validate data against these expectations.\n",
    "- Document data quality results and identify issues using Data Docs.\n",
    "- Understand how to integrate quality checks into data pipelines (conceptually).\n",
    "\n",
    "## Goals of this Workshop\n",
    "- Learn to design meaningful data quality checks applicable to real-world scenarios, such as building the data foundation for a flexible (AI) pricing system.\n",
    "- Gain experience using Great Expectations to define, validate, and visualize expectations and their results over time.\n",
    "\n",
    "## Dataset Information\n",
    "We'll be working with a modified version of the UCI Bike Sharing dataset (https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset). For simplicity and clarity in this workshop, we've made slight alterations to the columns and denormalized some measures (like temperature) to make them more intuitive."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "# - great_expectations (gx): The core library for defining and validating data expectations.\n",
    "# - sqlite3: Used to connect to and interact with our SQLite database containing the dataset.\n",
    "# - pandas (pd): Essential for data manipulation, analysis, and reading SQL query results.\n",
    "# - uuid: Used to generate unique identifiers for Great Expectations objects like Suites and Validators.\n",
    "import great_expectations as gx\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import uuid\n",
    "\n",
    "# Import utility functions specific to this workshop environment\n",
    "# - database: Contains functions to initialize and manage the workshop database.\n",
    "# - checker: Provides helper functions to check task completion.\n",
    "# - server: Includes functions to serve Great Expectations Data Docs locally.\n",
    "from utils import database\n",
    "from utils.checker import check_solution\n",
    "from utils.server import serve_docs, stop_server"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Initialize Environment and Explore Initial Data\n",
    "\n",
    "First, we need to set up our environment. This involves initializing a local SQLite database with the first part of our dataset (Rental Bike Data from Spring 2011) and establishing a connection to it. We'll then configure Great Expectations to use this database as a data source and take a first look at the data structure."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Initialize the database using the provided utility function.\n",
    "# This function typically resets the database, creates the necessary table schema,\n",
    "# and loads the initial dataset (Spring 2011 bike rentals).\n",
    "database.init()\n",
    "\n",
    "# Create a standard Python DB-API connection object to our SQLite database.\n",
    "# We'll use this connection for direct SQL queries with pandas later.\n",
    "conn = sqlite3.connect(\"database.db\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Obtain a Great Expectations Data Context.\n",
    "# The Data Context is the main entry point for the Great Expectations API,\n",
    "# managing configurations for Data Sources, Expectation Suites, and Validation Results.\n",
    "gx_context = gx.get_context()\n",
    "\n",
    "# Add our SQLite database as a Data Source within the Great Expectations context.\n",
    "# This tells Great Expectations how to connect to our data.\n",
    "# We give it a name ('sqlite_datasource') and provide the connection string.\n",
    "sqlite_data_source = gx_context.data_sources.add_sqlite(\n",
    "    name=\"sqlite_datasource\", connection_string=\"sqlite:///database.db\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define a Data Asset representing the table we want to validate.\n",
    "# An Asset is a logical representation of data (like a table or a query result)\n",
    "# within a Data Source that we want to apply expectations to.\n",
    "asset_name = \"bike_rental_asset\"\n",
    "database_table_name = \"bike_rental\" # The actual table name in the SQLite DB\n",
    "table_data_asset = sqlite_data_source.add_table_asset(\n",
    "    name=asset_name,\n",
    "    table_name=database_table_name\n",
    ")\n",
    "\n",
    "# Create a Batch Definition for the initial data load (Spring 2011).\n",
    "# A Batch Definition specifies *how* to fetch a batch of data from the asset.\n",
    "# Here, 'add_batch_definition_whole_table' means we want to validate the entire table\n",
    "# as a single batch for this initial dataset.\n",
    "spring_2011_batch_definition = table_data_asset.add_batch_definition_whole_table(\n",
    "    name=\"spring_2011_data\", # A descriptive name for this specific batch definition\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Fetch the actual data Batch based on the Batch Definition.\n",
    "# A Batch is the specific slice of data (in this case, the whole Spring 2011 table)\n",
    "# that we will run validations against.\n",
    "spring_2011_batch = spring_2011_batch_definition.get_batch()\n",
    "\n",
    "# Display the first few rows of the loaded Batch using its built-in head() method.\n",
    "# This provides a quick preview of the data's structure and content.\n",
    "# We select specific columns for a cleaner view.\n",
    "spring_2011_batch.head().data.loc[\n",
    "    :, [\"season\", \"weekday\", \"temp\", \"casual\", \"registered\", \"total\"]\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Perform direct SQL querying for initial exploration or investigation.\n",
    "# Here, we query the database directly (using pandas and our sqlite connection)\n",
    "# to examine records where the 'casual' rider count is exactly 2.\n",
    "# This type of ad-hoc analysis helps understand data distributions and identify potential anomalies\n",
    "# or patterns before defining formal expectations.\n",
    "query = \"\"\"\n",
    "SELECT season, weekday, temp, casual, registered, total\n",
    "FROM bike_rental\n",
    "WHERE casual = 2\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query and display the results using pandas\n",
    "pd.read_sql_query(query, conn)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Define and Validate Initial Expectations (Spring Data)\n",
    "\n",
    "Now that we've loaded and briefly explored the initial Spring 2011 data, let's define our first **Expectations**. Expectations are assertions or rules about what we expect from our data for it to be considered high quality. We'll start with some basic structural and content checks.\n",
    "\n",
    "### Basic Expectation Examples\n",
    "\n",
    "Great Expectations offers a wide range of built-in expectation types. You can explore the full list in the [Expectation Gallery](https://greatexpectations.io/expectations/). Here are a couple of common examples:\n",
    "\n",
    "1.  **Column Existence**: Ensure specific columns are present.\n",
    "    ```python\n",
    "    # Checks if a column named 'temp' exists\n",
    "    gx.expectations.ExpectColumnToExist(column=\"temp\")\n",
    "    ```\n",
    "\n",
    "2.  **Set Membership**: Verify that values in a categorical column belong to an allowed set.\n",
    "    ```python\n",
    "    # Checks if 'weathersit' values are only 1, 2, 3, or 4\n",
    "    gx.expectations.ExpectColumnValuesToBeInSet(\n",
    "        column=\"weathersit\", \n",
    "        value_set=[1, 2, 3, 4]  # 1:Clear, 2:Cloudy, 3:Light Rain, 4:Heavy Rain\n",
    "    )\n",
    "    ```\n",
    "\n",
    "We will now define and validate expectations against our `spring_2011_batch`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1: Check if the 'season' column exists."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# This is a fundamental structural check. \n",
    "# If critical columns are missing, downstream processing will likely fail.\n",
    "\n",
    "# Instantiate the Expectation object.\n",
    "### TASK_START ###\n",
    "# Define an expectation to check that the column named 'season' exists.\n",
    "# Look at the example in the markdown above or the Expectation Gallery.\n",
    "expectation = None # Replace None with your Expectation object\n",
    "### TASK_END ###\n",
    "\n",
    "# Validate the expectation against our Spring 2011 batch.\n",
    "# The `validate` method runs the expectation logic on the batch data.\n",
    "# `result_format=\"COMPLETE\"` provides detailed results, including observed values.\n",
    "result = spring_2011_batch.validate(expectation, result_format=\"COMPLETE\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Use the workshop's checker utility to verify the task result.\n",
    "check_solution(task=1, result=result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2: Check if the 'season' column *only* contains 'Spring'."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# Since we loaded only Spring data, we expect this to be true.\n",
    "# This checks for data consistency within this specific batch.\n",
    "\n",
    "### TASK_START ###\n",
    "# Define an expectation to check that the values in the 'season' column\n",
    "# belong to a specific set of allowed values. Initially, this set should\n",
    "# only contain the string 'Spring'. Refer to the Expectation Gallery for help.\n",
    "expectation = None # Replace None with your Expectation object\n",
    "### TASK_END ###\n",
    "\n",
    "# Validate this expectation against the same Spring 2011 batch.\n",
    "result = spring_2011_batch.validate(expectation, result_format=\"COMPLETE\")\n",
    "\n",
    "# Print the overall success status from the result object.\n",
    "# The expected result of this expectations should be \"False\", as there is an error in this dataset\n",
    "# So this Task succeeds if the expectations fails\n",
    "print(\"The expectation result is: \", result[\"success\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Use the workshop's checker utility.\n",
    "check_solution(task=2, result=result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "**Investigation:** The previous expectation failed! This indicates that our assumption was incorrect, and the 'season' column in the initial data contains values other than 'Spring'. To understand why, let's query the distinct values present in the 'season' column directly from the database."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Investigate why the ExpectColumnValuesToBeInSet expectation failed.\n",
    "# Query the database for all unique values in the 'season' column.\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT season\n",
    "FROM bike_rental\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query using pandas and the database connection.\n",
    "pd.read_sql_query(query, conn)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Cleaning:** The investigation revealed a data quality issue: a typo ('Sprung' instead of 'Spring'). In a real-world scenario, we might update the source or apply a transformation. For this workshop, we'll directly remove the offending rows from our database table to ensure the data conforms to our expectation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.3: Fix the data quality issue found."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "source": [
    "# Define a SQL query to delete rows where 'season' is not 'Spring'.\n",
    "# This is a direct manipulation for workshop purposes; in practice, data cleaning\n",
    "# might involve more complex logic or updating source systems.\n",
    "\n",
    "### TASK_START ###\n",
    "# Write a SQL DELETE statement to remove rows from the 'bike_rental' table\n",
    "# where the 'season' column does not have the value 'Spring'.\n",
    "query = \"\"\" \"\"\" # Write your SQL query between the triple quotes\n",
    "### TASK_END ###\n",
    "\n",
    "# Execute the DELETE query using the database connection.\n",
    "# Using 'with conn:' ensures the transaction is committed.\n",
    "with conn:\n",
    "    conn.execute(query)\n",
    "\n",
    "# IMPORTANT: Re-fetch the batch after modifying the underlying data.\n",
    "# Great Expectations batches often represent a snapshot; fetching it again ensures\n",
    "# we are validating the *cleaned* data.\n",
    "spring_2011_batch = spring_2011_batch_definition.get_batch()\n",
    "\n",
    "# Re-run the previous ExpectColumnValuesToBeInSet expectation to confirm the fix.\n",
    "# We expect this to succeed now.\n",
    "result = spring_2011_batch.validate(expectation, result_format=\"COMPLETE\")\n",
    "print(\"The expectation result is: \", result[\"success\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Use the workshop's checker utility.\n",
    "check_solution(task=3, result=result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unit tests can check for specific values, but Great Expectations excels at defining broader data characteristics and constraints. Let's explore an expectation that checks the range of a numeric column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.4: Add an expectation for the range of hourly bike rentals."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# First, let's find the actual minimum and maximum values of the 'total' column\n",
    "# in our current (cleaned Spring 2011) dataset to inform our expectation.\n",
    "# The 'total' column represents the total number of rentals in a given hour.\n",
    "\n",
    "# Write the SQL query to find the min and max of the 'total' column.\n",
    "### TASK_START ###\n",
    "# Write a SQL SELECT statement to find the minimum and maximum values\n",
    "# of the 'total' column in the 'bike_rental' table.\n",
    "query = \"\"\" \"\"\" # Write your SQL query here\n",
    "### TASK_END ###\n",
    "\n",
    "# Execute the query and print the result.\n",
    "print(pd.read_sql_query(query, conn))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.5: Define range expectation based on query."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Now, define an Expectation that the maximum value of the 'total' column\n",
    "# should fall within a certain range.\n",
    "# Based on the query result (max=638), let's set the range to be\n",
    "# 90% to 110% of the observed maximum. This allows for some variation\n",
    "# but flags significant deviations.\n",
    "observed_max = 638\n",
    "\n",
    "### TASK_START ###\n",
    "# Define an expectation to check that the maximum value of the 'total' column\n",
    "# is between 90% and 110% of the 'observed_max' value defined above.\n",
    "# Hint: Look for an expectation like 'ExpectColumnMaxToBeBetween'.\n",
    "expectation = None # Replace None with your Expectation object\n",
    "### TASK_END ###\n",
    "\n",
    "# Validate the expectation against the Spring 2011 batch.\n",
    "result = spring_2011_batch.validate(expectation, result_format=\"COMPLETE\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Use the workshop's checker utility.\n",
    "check_solution(task=4, result=result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Advanced Expectations and Data Docs Introduction\n",
    "\n",
    "Let's explore more sophisticated expectations, like validating data formats using regular expressions. We'll also introduce **Expectation Suites** and **Data Docs**, core Great Expectations concepts for organizing expectations and visualizing validation results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1: Validate the date format using a regular expression."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# The 'dteday' column should contain dates in 'YYYY-MM-DD' format.\n",
    "# We can enforce this using `ExpectColumnValuesToMatchRegex`.\n",
    "\n",
    "### TASK_START ###\n",
    "# Define the regex pattern for YYYY-MM-DD format.\n",
    "# Use \\d{4} for year, \\d{2} for month/day, and hyphens in between.\n",
    "# Remember to anchor the pattern using ^ and $.\n",
    "iso_date_regex = r\"\" # Define your regex pattern here\n",
    "\n",
    "# Define an expectation to check that values in the 'dteday' column\n",
    "# match the 'iso_date_regex' pattern you defined.\n",
    "# Hint: Look for 'ExpectColumnValuesToMatchRegex'.\n",
    "expectation = None # Replace None with your Expectation object\n",
    "\n",
    "# Note: A more precise regex could validate month/day ranges, e.g.: \n",
    "# regex=r\"^(?:(?:19|20)\\d\\d)-(0[1-9]|1[0-2])-(0[1-9]|[12][0-9]|3[01])$\"\n",
    "### TASK_END ###\n",
    "\n",
    "# Validate the expectation against the Spring 2011 batch.\n",
    "result = spring_2011_batch.validate(expectation, result_format=\"COMPLETE\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Use the workshop's checker utility to verify the task result.\n",
    "check_solution(task=5, result=result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Print the list of values that did *not* match the expected format.\n",
    "# In this initial dataset, we expect this list to be empty.\n",
    "print(\"These are the unexpected values:\", \", \".join(result[\"result\"][\"unexpected_list\"]))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excursion: Expectation Suites and Data Docs\n",
    "\n",
    "So far, we've defined and validated expectations one by one. For real projects, you'll want to group related expectations together and visualize the results clearly.\n",
    "\n",
    "-   **Expectation Suite**: A collection of expectations defined for a specific data asset (like our bike rental table). Think of it as a test suite for your data.\n",
    "-   **Data Docs**: Automatically generated HTML documentation displaying expectation definitions and validation results. They provide a clear, shareable report on data quality.\n",
    "\n",
    "Let's create our first Expectation Suite and see how Data Docs work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cheatsheet for Key Great Expectations Concepts\n",
    "-   ***Data Context***: The main entry point for managing GX objects (Data Sources, Suites, etc.).\n",
    "-   ***Data Source***: Configuration for connecting to a data system (like our SQLite DB).\n",
    "-   ***Data Asset***: A logical representation of data (e.g., a table) within a Data Source.\n",
    "-   ***Batch Definition***: Specifies how to fetch a slice of data (a Batch) from an Asset.\n",
    "-   ***Batch***: A specific slice of data retrieved based on a Batch Definition, ready for validation.\n",
    "-   ***Expectation***: A verifiable assertion or rule about your data.\n",
    "-   ***Expectation Suite***: A collection of Expectations, typically applied together to a Data Asset.\n",
    "-   ***Validation Definition***: Links an Expectation Suite to a Batch Definition, defining *what* to validate against *which* data.\n",
    "-   ***Validation Result***: The outcome of running a Validation Definition on a Batch.\n",
    "-   ***Checkpoint***: A bundle of Validation, Batches and Expectations Suites that can be re-run (also with different Batches). Its most powerful feature is being able to run Actions (see below). Checkpoints are essential for pipeline workflows.\n",
    "-   ***Actions***: Can be carried out after a checkpoint is run. Mostly used for notification or updating the Data Docs, but can be costumized as desired.\n",
    "-   ***Data Docs***: Human-readable HTML reports generated from Expectation Suites and Validation Results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conceptual Workflow\n",
    "![](./img/gx_workflow_steps_and_components.png)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create an Expectation Suite.\n",
    "\n",
    "# Define a unique name for our first Expectation Suite.\n",
    "# Using UUID ensures the name is unique, especially if running the notebook multiple times.\n",
    "suite_name = \"bike_rental_suite_\" + str(uuid.uuid4())\n",
    "\n",
    "# Create an empty Expectation Suite object.\n",
    "initial_expectation_suite = gx.ExpectationSuite(name=suite_name)\n",
    "\n",
    "# Add some basic expectations to the suite.\n",
    "# These check that the 'total' and 'dteday' columns should not contain null values.\n",
    "initial_expectation_suite.add_expectation(\n",
    "    gx.expectations.ExpectColumnValuesToNotBeNull(column = 'total')\n",
    ")\n",
    "initial_expectation_suite.add_expectation(\n",
    "    gx.expectations.ExpectColumnValuesToNotBeNull(column = 'dteday')\n",
    ")\n",
    "\n",
    "# Add and save the suite to the Great Expectations context.\n",
    "# This makes the suite persistent within the context's configured store.\n",
    "initial_expectation_suite = gx_context.suites.add(initial_expectation_suite)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create a Validation Definition.\n",
    "# A Validation Definition links an Expectation Suite to a Batch Definition.\n",
    "# It specifies *which suite* to run against *which data batch*.\n",
    "\n",
    "# Define a unique name for the Validation Definition.\n",
    "validation_name = \"spring_data_validation_\" + str(uuid.uuid4())\n",
    "\n",
    "# Create the ValidationDefinition object.\n",
    "spring_validation_definition = gx.ValidationDefinition(\n",
    "    name=validation_name, # Unique identifier for this validation setup\n",
    "    data=spring_2011_batch_definition, # Use the batch definition for Spring 2011 data\n",
    "    suite=initial_expectation_suite, # Use the suite we just created\n",
    ")\n",
    "\n",
    "# Add and save the Validation Definition to the context.\n",
    "spring_validation_definition = gx_context.validation_definitions.add(spring_validation_definition)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2: Run the Validation Definition."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Calling `.run()` on the Validation Definition executes all expectations in the associated suite\n",
    "# against a batch of data specified by the associated batch definition.\n",
    "\n",
    "### TASK_START ###\n",
    "# Run the 'spring_validation_definition' that we just created.\n",
    "# Store the output in the 'validation_results' variable.\n",
    "validation_results = None # Replace None with the method call\n",
    "### TASK_END ###\n",
    "\n",
    "# Print the validation results.\n",
    "# The output is a JSON-like object containing overall success status, results for each expectation,\n",
    "# observed values, and metadata about the validation run.\n",
    "print(validation_results)\n",
    "\n",
    "# Hint: In Jupyter Lab/VS Code, you might need to right-click the output and choose\n",
    "# 'Open With -> Text Editor' or similar to view the full JSON structure easily."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Use the workshop's checker utility to verify the task result.\n",
    "check_solution(task=6, result=validation_results)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Build and View Data Docs.\n",
    "# Great Expectations can generate HTML documentation from your suites and validation results.\n",
    "\n",
    "# This command builds the Data Docs based on the suites and results stored in the context.\n",
    "# It returns the path to the local directory where the docs were built.\n",
    "data_doc_site_path = gx_context.build_data_docs()['local_site']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Use the workshop utility to start a simple local HTTP server\n",
    "# to view the generated Data Docs in your browser.\n",
    "server_instance, server_thread = serve_docs(data_doc_site_path, port=8003, open_browser=False)\n",
    "# Note: 'open_browser=False' prevents automatic opening; manually click the link above."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explore Data Docs:** Open the link provided in the output above (e.g., `http://localhost:8003/`).\n",
    "\n",
    "Navigate through the Data Docs site:\n",
    "-   Find the **Validation Results** section.\n",
    "-   Click on the latest validation run (associated with `bike_rental_suite_...`).\n",
    "-   Examine the results for each expectation (expect_column_values_to_not_be_null). See how the observed values compare to the expected criteria.\n",
    "-   Explore the **Expectation Suites** section to see the definition of the suite itself.\n",
    "\n",
    "Take a few minutes to familiarize yourself with the structure and information presented in Data Docs."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Stop the local Data Docs server once you are finished exploring.\n",
    "# It's good practice to release the port.\n",
    "if 'server_instance' in locals() and server_instance:\n",
    "    stop_server(server_instance, server_thread)\n",
    "    # Clean up variables to prevent accidental reuse\n",
    "    del server_instance\n",
    "    del server_thread\n",
    "else:\n",
    "    print(\"Server was not started or already stopped.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Evolving the Expectation Suite by Loading Summer Data\n",
    "\n",
    "Data often changes over time (new categories appear, ranges shift). Expectation Suites should evolve to reflect these changes. Let's imagine that Summer data will be added soon. We need to update our `initial_expectation_suite` to allow 'Summer' in the 'season' column, in addition to the 'Spring' we already cleaned for."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Lets move to the next step in the workshop, add the summer data.\n",
    "database.set_step(1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.1: Add an expectation allowing 'Spring' or 'Summer' in the 'season' column."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# We create a new expectation instance reflecting this updated requirement.\n",
    "\n",
    "### TASK_START ###\n",
    "# Define an 'ExpectColumnValuesToBeInSet' expectation for the 'season' column\n",
    "# that allows *both* 'Spring' and 'Summer' as valid values in the value_set.\n",
    "updated_season_expectation = None # Replace None with your Expectation object\n",
    "### TASK_END ###\n",
    "\n",
    "# Add this new/updated expectation to our existing suite.\n",
    "# Note: If an expectation for the same column and type already exists,\n",
    "# `add_expectation` often replaces it (behavior might vary slightly by GX version).\n",
    "# It's generally safer to manage suites explicitly if precise control over replacement is needed.\n",
    "initial_expectation_suite.add_expectation(updated_season_expectation)\n",
    "\n",
    "# We can immediately re-run our existing validation definition.\n",
    "# This will run the *updated* suite against the *original Spring data*.\n",
    "# This specific expectation ('Spring' or 'Summer') should still pass against the Spring data.\n",
    "validation_results = spring_validation_definition.run()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Use the workshop's checker utility to verify the task result.\n",
    "check_solution(task=7, result=validation_results)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4.2 (Optional but good practice): Create a new Validation Definition for clarity."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# While we could reuse `spring_validation_definition`, creating a new one makes it clear\n",
    "# that this validation run uses the *updated* suite.\n",
    "validation_name_updated = \"spring_data_validation_updated_\" + str(uuid.uuid4())\n",
    "\n",
    "### TASK_START ###\n",
    "# Create a *new* gx.ValidationDefinition object.\n",
    "# Use the new 'validation_name_updated'.\n",
    "# For the 'data' argument, use the *original* 'spring_2011_batch_definition'.\n",
    "# For the 'suite' argument, use the 'initial_expectation_suite' (which we just updated).\n",
    "spring_validation_definition_updated = None # Replace None with your ValidationDefinition object\n",
    "### TASK_END ###\n",
    "\n",
    "# Add the new validation definition to the context.\n",
    "spring_validation_definition_updated = gx_context.validation_definitions.add(\n",
    "    spring_validation_definition_updated\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Run the new Validation Definition.\n",
    "# This explicitly runs the updated suite against the Spring data.\n",
    "### TASK_START ###\n",
    "# Run the 'spring_validation_definition_updated' that you created in the previous cell.\n",
    "# Store the results in the 'results' variable.\n",
    "results = None # Replace None with the method call\n",
    "print(results)\n",
    "### TASK_END ###\n",
    "\n",
    "# Hint: Check the output JSON. You should see the 'expect_column_values_to_be_in_set' \n",
    "# expectation now lists [\"Spring\", \"Summer\"] in its configuration, and it should succeed."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Rebuild and view Data Docs to see the history.\n",
    "\n",
    "# Build the data docs again. This incorporates the latest validation run.\n",
    "data_doc_site_path = gx_context.build_data_docs()['local_site']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Serve the updated Data Docs on a different port (e.g., 8005).\n",
    "server_instance, server_thread = serve_docs(data_doc_site_path, port=8005, open_browser=False)\n",
    "# Explore the Data Docs again. Notice the new validation run listed.\n",
    "# You can compare runs and see how the suite definition has changed over time."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Stop the Data Docs server when finished.\n",
    "if 'server_instance' in locals() and server_instance:\n",
    "    stop_server(server_instance, server_thread)\n",
    "    del server_instance\n",
    "    del server_thread\n",
    "else:\n",
    "    print(\"Server was not started or already stopped.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Validating Seasonal Expectations & Monthly Batches\n",
    "\n",
    "Now, let's load data for the next season (Fall 2011) into our database. We'll then explore defining expectations on specific subsets (batches) of data, such as focusing only on a particular month."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load Fall 2011 data into the database.\n",
    "# The `database.set_step(2)` utility function handles adding the data for these seasons.\n",
    "database.set_step(2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define a new Batch Definition and Batch for the updated data.\n",
    "# Since the underlying table 'bike_rental' now contains more data (Spring, Summer, Fall),\n",
    "# we define a new batch definition to represent this current state.\n",
    "fall_2011_batch_definition = table_data_asset.add_batch_definition_whole_table(\n",
    "    name=\"data_through_fall_2011\", # Represents data up to and including Fall 2011\n",
    ")\n",
    "\n",
    "# Get the corresponding Batch object containing Spring, Summer, and Fall data.\n",
    "fall_2011_batch = fall_2011_batch_definition.get_batch()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.1: Analyze monthly trends in bike rentals."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Before setting month-specific expectations, let's see how the average\n",
    "# total rentals ('total') varies by month ('mnth') in the data loaded so far.\n",
    "# This helps understand seasonal patterns.\n",
    "\n",
    "### TASK_START ###\n",
    "# Write a SQL query to calculate the average of the 'total' column,\n",
    "# grouped by the 'mnth' column. Optionally, order the results by month.\n",
    "query = \"\"\" \"\"\" # Write your SQL query here\n",
    "### TASK_END ###\n",
    "\n",
    "# Execute the query and display the monthly averages.\n",
    "print(pd.read_sql_query(query, conn))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introducing Monthly Batch Definitions:**\n",
    "Great Expectations allows defining batches based on data splitting criteria, such as time columns. This is useful for validating data incrementally (e.g., daily, monthly) or applying different rules to different periods. We'll create a *monthly* batch definition based on the 'dteday' column."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create a dedicated Expectation Suite for October data.\n",
    "# Sometimes, we might want specific checks only for certain periods.\n",
    "# Let's create a new suite focused on validating October (month=10) data.\n",
    "\n",
    "# Define a unique name for the October suite.\n",
    "october_suite_name = \"october_rules_suite_\" + str(uuid.uuid4())\n",
    "\n",
    "# Create the expectation: Check if the month ('mnth' column) is indeed 10.\n",
    "# This acts as a sanity check for the batching mechanism.\n",
    "expect_month_is_october = gx.expectations.ExpectColumnValuesToBeInSet(\n",
    "    column='mnth',\n",
    "    value_set=[10], # Only allow month 10\n",
    ")\n",
    "\n",
    "# Suggestion: A more meaningful expectation for October might be:\n",
    "# Based on the previous query, the average for month 10 was ~166.\n",
    "# expect_oct_mean = gx.expectations.ExpectColumnMeanToBeBetween(\n",
    "#     column='total',\n",
    "#     min_value=166 * 0.8, # e.g., 80% of observed mean\n",
    "#     max_value=166 * 1.2, # e.g., 120% of observed mean\n",
    "# )\n",
    "\n",
    "# Create the new suite.\n",
    "expectation_suite_october = gx.ExpectationSuite(name=october_suite_name)\n",
    "\n",
    "# Add the month check expectation to this suite.\n",
    "expectation_suite_october.add_expectation(expect_month_is_october)\n",
    "# expectation_suite_october.add_expectation(expect_oct_mean) # Add the mean check if desired\n",
    "\n",
    "# Add and save the October-specific suite to the context.\n",
    "expectation_suite_october = gx_context.suites.add(expectation_suite_october)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.2: Create a Monthly Batch Definition."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# We'll use a different data asset name here ('rentals_monthly_asset')\n",
    "# to keep this batching strategy separate, although it points to the same table.\n",
    "monthly_table_asset = sqlite_data_source.add_table_asset(\n",
    "    name=\"rentals_monthly_asset\", table_name=database_table_name\n",
    ")\n",
    "\n",
    "# Create a batch definition that splits the data by year and month based on the 'dteday' column.\n",
    "### TASK_START ###\n",
    "# Use the 'monthly_table_asset' to add a *monthly* batch definition.\n",
    "# Give it a name (e.g., 'monthly_batches').\n",
    "# Specify that the splitting should be based on the 'dteday' column.\n",
    "# Hint: Look for methods on the table asset like 'add_batch_definition_...' related to time splitting.\n",
    "batch_definition_monthly = None # Replace None with the method call\n",
    "### TASK_END ###\n",
    "\n",
    "# List the available batch identifiers (year, month combinations) found in the data.\n",
    "# This shows how GX has identified the distinct months present.\n",
    "batch_definition_monthly.get_batch_identifiers_list()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Use the workshop's checker utility to verify the task result.\n",
    "check_solution(task=8, result=batch_definition_monthly)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create a Validation Definition for the October data.\n",
    "# This definition links our *monthly batch definition* to the *October-specific suite*.\n",
    "october_validation_definition = gx.ValidationDefinition(\n",
    "    name=\"validate_october_data\",\n",
    "    data=batch_definition_monthly,     # Use the monthly batch definition\n",
    "    suite=expectation_suite_october, # Use the suite with October rules\n",
    ")\n",
    "\n",
    "# Add and save this definition to the context.\n",
    "# Note: We don't add this to the context here as it's run immediately after,\n",
    "# but in a persistent setup, you would typically add it.\n",
    "# october_validation_definition = gx_context.validation_definitions.add(october_validation_definition)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Run validation specifically for October 2011.\n",
    "# When running a validation definition based on a splitter (like monthly),\n",
    "# we provide `batch_parameters` to select the specific batch(es) to validate.\n",
    "validation_result_october = october_validation_definition.run(\n",
    "    batch_parameters={\"year\": 2011, \"month\": 10} # Select only Oct 2011 data\n",
    ")\n",
    "\n",
    "# Print the success status of the October validation.\n",
    "validation_result_october[\"success\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Adding Custom Expectations\n",
    "\n",
    "Great Expectations has a rich library of built-in expectations ([Expectation Gallery](https://greatexpectations.io/expectations/)), but sometimes you need checks specific to your business logic that aren't covered. You can create custom expectations, often by leveraging SQL queries.\n",
    "\n",
    "First, let's load the Winter 2011 data and then define a custom expectation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load Winter 2011 data.\n",
    "# `database.set_step(3)` adds the winter data to the existing table.\n",
    "database.set_step(3)\n",
    "\n",
    "# Verify that all four seasons are now present in the 'season' column.\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT season\n",
    "FROM bike_rental\n",
    "ORDER BY season -- Optional ordering\n",
    "\"\"\"\n",
    "# Execute the query\n",
    "pd.read_sql_query(query, conn)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Review existing expectations in our main suite.\n",
    "# Let's programmatically list the expectations currently in `initial_expectation_suite`.\n",
    "print(\"Current expectations in the suite:\")\n",
    "for expectation_config in initial_expectation_suite.expectations:\n",
    "    # Access attributes like expectation_type or kwargs['column']\n",
    "    print(f\"- Expectation Type: '{expectation_config.expectation_type}', Column: '{expectation_config.column}'\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6.1: Define a custom expectation using SQL."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# We want to ensure data integrity by checking if the sum of 'casual' and 'registered'\n",
    "# always equals the 'total' column.\n",
    "# We can use `UnexpectedRowsExpectation`, which expects a SQL query that returns *rows that violate* the condition.\n",
    "# The expectation passes if the query returns zero rows.\n",
    "\n",
    "### TASK_START ###\n",
    "# Write a SQL query that selects all columns (*) from the batch\n",
    "# where the sum of the 'casual' and 'registered' columns is NOT equal to the 'total' column.\n",
    "# IMPORTANT: Use the placeholder '{batch}' instead of the actual table name 'bike_rental'.\n",
    "# Great Expectations will replace '{batch}' correctly during validation.\n",
    "sum_check_query =\"\"\" \"\"\" # Write your SQL query here, remembering to use {batch}\n",
    "### TASK_END ###\n",
    "\n",
    "# Instantiate the custom expectation.\n",
    "expect_casual_registered_sum_total = gx.expectations.UnexpectedRowsExpectation(\n",
    "    unexpected_rows_query=sum_check_query,\n",
    "    description=\"Check that the sum of casual and registered riders equals the total count\", # Optional: description for Data Docs\n",
    ")\n",
    "\n",
    "# Get a batch representing the data up to Winter 2011\n",
    "# We need a batch definition that covers all the data currently loaded.\n",
    "winter_2011_batch_definition = table_data_asset.add_batch_definition_whole_table(\n",
    "    name=\"data_through_winter_2011\"\n",
    ")\n",
    "winter_2011_batch = winter_2011_batch_definition.get_batch()\n",
    "\n",
    "# Validate this single custom expectation against the full 2011 data.\n",
    "result = winter_2011_batch.validate(\n",
    "    expect_casual_registered_sum_total,\n",
    "    result_format=\"COMPLETE\",\n",
    ")\n",
    "\n",
    "# You can inspect the 'result' object to see if any unexpected rows were found.\n",
    "print(result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Use the workshop's checker utility to verify the task result.\n",
    "check_solution(task=9, result=result)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Add the custom expectation to our main suite.\n",
    "# This ensures the check is included in future validation runs of this suite.\n",
    "initial_expectation_suite.add_expectation(expect_casual_registered_sum_total)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Validating Future Data (Year 2012)\n",
    "\n",
    "A key use case for data quality testing is detecting **data drift** or unexpected changes when new data arrives. Let's load the data for the entire year 2012 and run our established Expectation Suite against it. Will our assumptions from 2011 still hold? For this task, you don’t need to modify the code—just review the validation results to build a better understanding for the next task."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load the full dataset for the year 2012.\n",
    "# `database.set_step(4)` adds all data from 2012 (all seasons) to the table.\n",
    "database.set_step(4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Validate the full 2011+2012 dataset against our main suite.\n",
    "\n",
    "# Create a batch definition representing the entire table, now containing 2011 and 2012 data.\n",
    "# We use the original 'table_data_asset' defined earlier.\n",
    "full_dataset_batch_definition = table_data_asset.add_batch_definition_whole_table(\n",
    "    name=\"full_dataset_2011_2012\",\n",
    ")\n",
    "\n",
    "# Create a Validation Definition linking this full dataset batch to our main suite.\n",
    "full_data_validation_definition = gx.ValidationDefinition(\n",
    "    name=\"validate_full_dataset\",\n",
    "    data=full_dataset_batch_definition,\n",
    "    suite=initial_expectation_suite, # Use the suite containing all our general rules\n",
    ")\n",
    "\n",
    "# Run the validation.\n",
    "validation_results_full = full_data_validation_definition.run(result_format=\"COMPLETE\")\n",
    "\n",
    "# Print the results.\n",
    "# Pay close attention to the 'success' field and individual expectation results.\n",
    "print(validation_results_full)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Data Quality for AI/ML Models\n",
    "\n",
    "While the previous checks ensure general data integrity, AI/ML models often have specific requirements. Features need to be within expected ranges, categorical values must be consistent, and relationships between columns (like `weekday` and `workingday`) must hold true for the model to learn meaningful patterns.\n",
    "\n",
    "In this section, we'll:\n",
    "1.  Train a simple bike rental prediction model on the *current* dataset (potentially containing errors).\n",
    "2.  Define a new Expectation Suite (`ml_suite`) with checks specifically relevant to the model's features (e.g., valid ranges for `hour`, `temp`, `humidity`, consistency between `weekday` and `workingday`).\n",
    "3.  Validate the full dataset against this `ml_suite` to identify issues.\n",
    "4.  Clean the data based on the validation failures.\n",
    "5.  Retrain the model on the *cleaned* data and observe the potential improvement in performance.\n",
    "\n",
    "This demonstrates how Great Expectations can be a crucial step in preparing data for reliable model training."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Import the model training utility\n",
    "from utils.model import train_and_evaluate_model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Initial Model\n",
    "First, let's train a baseline model on the data as it currently exists in the database (including 2011 and 2012)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df = pd.read_sql_query(\"SELECT * FROM bike_rental\", conn)\n",
    "print(\"Training initial model on potentially unvalidated data...\")\n",
    "train_and_evaluate_model(df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8.1: Define AI/ML-Specific Expectations\n",
    "Now, let's create a list of expectations tailored for the features used by our model. These include checking valid ranges for numerical features and consistency between related categorical/binary features."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "### TASK_START ###\n",
    "# Define a list of expectations relevant for an ML model using this data.\n",
    "# Consider the features used in the model training function ('hour', 'temp', 'humidity', 'workingday', 'weekday', 'holiday').\n",
    "# Add expectations such as:\n",
    "# 1. 'hour' is between 0 and 23.\n",
    "# 2. 'temp' is within a reasonable range (e.g., -40 to 60 C).\n",
    "# 3. 'humidity' is between 0 and 100.\n",
    "# 4. Custom SQL Check (UnexpectedRowsExpectation): 'workingday' should not be 1 on 'Saturday' or 'Sunday'.\n",
    "# 5. Custom SQL Check (UnexpectedRowsExpectation): 'workingday' should not be 0 on a weekday ('Monday' through 'Friday') unless 'holiday' is 1.\n",
    "# Remember to use the '{batch}' placeholder in your SQL queries.\n",
    "expectations = [\n",
    "    # Add your gx.expectations objects here\n",
    "]\n",
    "### TASK_END ###\n",
    "\n",
    "# Create the ML-specific Expectation Suite\n",
    "ml_suite = gx.ExpectationSuite(\n",
    "    name=\"bike_rental_ml_suite_\" + str(uuid.uuid4()),\n",
    "    expectations=expectations,\n",
    ")\n",
    "# Add the suite to the context\n",
    "ml_suite = gx_context.suites.add(ml_suite)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Data with ML Suite\n",
    "Let's create a validation definition linking our full dataset batch to this new ML-focused suite and run the validation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create the validation definition using the full dataset batch and the ML suite\n",
    "validation_definition = gx.ValidationDefinition(\n",
    "    name=\"ml_validation_definition_\" + str(uuid.uuid4()),\n",
    "    data=full_dataset_batch_definition,\n",
    "    suite=ml_suite\n",
    ")\n",
    "# Add the validation definition to the context\n",
    "validation_definition = gx_context.validation_definitions.add(validation_definition)\n",
    "\n",
    "# Run the validation definition and analyze the results.\n",
    "ml_validation_results = validation_definition.run(result_format=\"COMPLETE\")\n",
    "print(ml_validation_results)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8.2: Clean Data Based on Validation Results\n",
    "The validation results likely highlighted rows violating our ML-specific expectations (e.g., incorrect `workingday` flags, potentially invalid `hour`, `temp`, or `humidity` values if errors were present). Based on these findings, we define a SQL query to remove the offending rows. *Note: In a real-world scenario, you might investigate these rows further or apply transformations instead of outright deletion.*"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Based on the validation results, we define a query to remove rows failing the checks.\n",
    "\n",
    "### TASK_START ###\n",
    "# Write a SQL DELETE statement for the 'bike_rental' table.\n",
    "# The WHERE clause should combine conditions to remove rows that violate\n",
    "# the expectations defined in the previous task (Task 8.1).\n",
    "query = \"\"\" \"\"\" # Write your SQL DELETE query here\n",
    "### TASK_END ###\n",
    "\n",
    "# Execute the DELETE query using the database connection.\n",
    "# Using 'with conn:' ensures the transaction is committed.\n",
    "print(\"Cleaning data based on ML validation results...\")\n",
    "with conn:\n",
    "    cursor = conn.execute(query)\n",
    "    print(f\"{cursor.rowcount} rows removed.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain Model on Cleaned Data\n",
    "Finally, we fetch the cleaned data and retrain our model. Compare the evaluation metrics (like Mean Squared Error) with the initial model's performance to see the impact of data quality improvements."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Fetch the cleaned data\n",
    "df_cleaned = pd.read_sql_query(\"SELECT * FROM bike_rental\", conn)\n",
    "\n",
    "# Retrain and evaluate the model on the cleaned dataset\n",
    "print(\"\\nTraining model on cleaned data...\")\n",
    "train_and_evaluate_model(df_cleaned)\n",
    "\n",
    "print(\"\\nCompare the MAE (lower is better) between the initial and retrained models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Task\n",
    "\n",
    "Congratulations on completing all the tasks in this workshop!  \n",
    "If you're eager to explore further, feel free to experiment with additional expectations or rebuild the entire Great Expectations workflow from scratch. This section offers limited guidance, giving you the freedom to apply what you've learned and deepen your understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First observe the data to decide what kind of validations you want to do. \n",
    "pd.read_sql_query(\"SELECT * FROM bike_rental\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case you want a better understanding of the values of the data you can query averages, \n",
    "# sums or other calculations by filling the quotes below.\n",
    "query = \"\"\" \"\"\"\n",
    "\n",
    "pd.read_sql_query(query, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After analyzing the data, you may have identified certain requirements or constraints for specific fields. For instance, you might have noticed that humidity values should range between 0 and 100, or that \"super bad\" weather events typically occur only in winter. You may have also uncovered relationships between multiple columns that would be ideal candidates for custom expectations.\n",
    "\n",
    "To implement a complete validation workflow, assemble the following components:\n",
    "\n",
    "1. **Context**\n",
    "2. **SQL Data Source** (use the same source as in the previous task)\n",
    "3. **Asset**\n",
    "4. **Batch Definition**\n",
    "5. **Expectations and Expectation Suite**\n",
    "6. **Validation Configuration**\n",
    "7. **Data Docs** (optional)\n",
    "\n",
    "If you're looking for inspiration, consider the following suggestion:\n",
    "\n",
    "> Implement validation rules for minimum and maximum temperatures, incorporating seasonal constraints for January, April, July, and October. Since temperature thresholds vary by season, define different limits for each of these months. Aim to use a single expectation suite, reapplying it across validation runs. This can be achieved by utilizing parameters or dynamically updating expectation values. Refer to the [Great Expectations Documentation](https://docs.greatexpectations.io/docs/core/introduction/) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before defining the expectations start from the beginning and and setup the connection to the data. \n",
    "# Also decide how to batch the data. GX supports batching based on date and can divide into \n",
    "# daily, weekly, monthly, yearly or full table batch.\n",
    "# Start the new task by creating a new gx context.\n",
    "\n",
    "### TASK START ###\n",
    "my_gx_context = None # replace None and add more code above\n",
    "\n",
    "### TASK END ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the expectations and test it on the data. Depending on your goal you might want to run the validations multiple times\n",
    "\n",
    "### TASK START ###\n",
    "\n",
    "### SOLUTION END ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start and observe Data Docs. Make sure you are using a new port in case the \n",
    "# data docs of the previous tasks are still running.\n",
    "\n",
    "### TASK START ###\n",
    "\n",
    "### TASK END ###\n",
    "\n",
    "# Stop the Data Docs server when finished.\n",
    "if 'server_instance' in locals() and server_instance:\n",
    "    stop_server(server_instance, server_thread)\n",
    "    del server_instance\n",
    "    del server_thread\n",
    "else:\n",
    "    print(\"Server was not started or already stopped.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Workshop Environment",
   "language": "python",
   "name": "workshop-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
